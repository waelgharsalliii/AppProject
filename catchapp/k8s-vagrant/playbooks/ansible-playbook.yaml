- name: Setup Kubernetes Environment
  hosts: all
  become: yes
  become_method: sudo
  gather_facts: yes
  vars:
    pod_network_cidr: 192.168.0.0/16
    custom_resource_remote_src: /tmp/calico-custom-resource.yaml
    join_cluster_remote_src: /tmp/joincluster
    helm_chart_path: /home/vagrant/catch-app
  tasks:

    - name: Remove generated ubuntu hosts from /etc/hosts
      lineinfile:
        path: /etc/hosts
        regexp: "ubuntu-*"
        state: absent
        backup: yes

    - name: Remove generated hosts from /etc/hosts
      lineinfile:
        path: /etc/hosts
        regexp: ".* {{ hostvars[item]['ansible_hostname']}} {{ hostvars[item]['ansible_hostname']}}"
        state: absent
        backup: yes
      with_items: "{{ ansible_play_batch }}"

    - name: Update /etc/hosts with new host entries
      lineinfile:
        path: /etc/hosts
        regexp: ".*\t{{ hostvars[item]['ansible_hostname']}}\t{{ hostvars[item]['ansible_hostname']}}"
        line: "{{ hostvars[item]['ansible_ssh_host'] }}\t{{ hostvars[item]['ansible_hostname']}}\t{{ hostvars[item]['ansible_hostname']}}.local"
        state: present
        backup: yes
      with_items: "{{ ansible_play_batch }}"

    - name: Install packages that allow apt to be used over HTTPS
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg-agent
          - software-properties-common
        state: present
        update_cache: yes

    - name: Add an apt signing key for Docker
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add apt repository for Docker stable version
      apt_repository:
        repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_lsb.codename }} stable
        state: present

    - name: Install Docker and dependencies
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
        state: present
        update_cache: yes
      notify: Check docker status

    - name: Configure containerd
      copy:
        src: "{{ item.src }}"
        dest: "{{ item.dest }}"
      with_items:
        - { src: config.toml, dest: /etc/containerd/config.toml }

    - name: Reload systemd daemon
      command: systemctl daemon-reload

    - name: Enable and start containerd
      service:
        name: containerd
        state: restarted
        enabled: yes

    - name: Add current user to docker group
      user:
        name: "{{ ansible_user }}"
        groups: docker
        append: yes

    - name: Remove swapfile from /etc/fstab
      mount:
        name: "{{ item }}"
        fstype: swap
        state: absent
      with_items:
        - swap
        - none

    - name: Disable swap
      command: swapoff -a
      when: ansible_swaptotal_mb > 0

    - name: Ensure apt keyrings directory exists
      file:
        path: /etc/apt/keyrings
        state: directory

    - name: Delete Kubernetes keyrings if they exist
      file:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        state: absent

    - name: Add Kubernetes APT repository key
      shell: >
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: Add Kubernetes repository to sources list
      apt_repository:
        repo: deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /
        state: present
        filename: kubernetes
        update_cache: yes

    - name: Install Kubernetes binaries
      apt:
        name:
          - kubelet=1.29.*
          - kubeadm=1.29.*
          - kubectl=1.29.*
        state: present
        update_cache: yes

    - name: Ensure /etc/default/kubelet exists
      file:
        path: /etc/default/kubelet
        state: touch

    - name: Configure node IP in /etc/default/kubelet
      lineinfile:
        path: /etc/default/kubelet
        line: KUBELET_EXTRA_ARGS=--node-ip={{ node_ip }}
        state: present

    - name: Restart kubelet service
      service:
        name: kubelet
        state: restarted
        daemon_reload: yes
        enabled: yes

  handlers:
    - name: Check Docker status
      service:
        name: docker
        state: started
        enabled: yes

    - name: Restart kubelet
      service:
        name: kubelet
        state: restarted

- name: Master Node Setup
  hosts: master_nodes
  become: yes
  become_method: sudo
  gather_facts: yes
  vars:
    pod_network_cidr: 192.168.0.0/16
    custom_resource_remote_src: /tmp/calico-custom-resource.yaml
    join_cluster_remote_src: /tmp/joincluster
  tasks:

    - name: Check if Kubernetes API server is running
      shell: "systemctl is-active kube-apiserver"
      register: apiserver_status
      failed_when: false
      changed_when: false
    
    - name: Check if Kubernetes manifest files exist
      stat:
        path: /etc/kubernetes/manifests/kube-apiserver.yaml
      register: apiserver_manifest
    
    - name: Initialize Kubernetes cluster if not already initialized
      command: kubeadm init --apiserver-advertise-address="{{ ansible_ssh_host }}" --apiserver-cert-extra-sans="{{ ansible_ssh_host }}" --node-name {{ ansible_hostname }} --pod-network-cidr={{ pod_network_cidr }}
      register: kubeadm_status
      when: apiserver_status.rc != 0 and not apiserver_manifest.stat.exists
    
    - name: Setup kubeconfig for {{ ansible_user }} user
      command: "{{ item }}"
      with_items:
        - mkdir -p /home/{{ ansible_user }}/.kube
        - cp -i /etc/kubernetes/admin.conf /home/{{ ansible_user }}/.kube/config
        - chown {{ ansible_user }}:{{ ansible_user }} /home/{{ ansible_user }}/.kube/config
      when: kubeadm_status is defined and kubeadm_status | default({}) | length > 0 and kubeadm_status.rc is defined and kubeadm_status.rc == 0
      failed_when: kubeadm_status is not defined or kubeadm_status.rc is not defined
    
        
    #- name: Ensure API server is ready before applying Calico
     # command: kubectl get nodes
     # register: api_server_check
      #retries: 15
      #delay: 10
      #until: api_server_check.rc == 0
      #changed_when: false
    
    - name: Check if Calico pod network is installed
      command: kubectl get pods -n kube-system -l k8s-app=calico-node
      register: calico_status
      failed_when: false
      changed_when: false
    
    - name: Install Calico pod network if not installed
      command: kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/tigera-operator.yaml --validate=false
      when: calico_status.rc != 0 


    - name: Copy Calico custom resource
      template:
        src: calico-custom-resource.yaml.j2
        dest: "{{ custom_resource_remote_src }}"
      when: calico_status.rc != 0

    - name: Install custom resource pod network
      command: kubectl create -f {{ custom_resource_remote_src }}
      register: install_calico_custom_resource
      when: calico_status.rc != 0

    - name: Generate and save cluster join command
      command: kubeadm token create --print-join-command
      register: join_cluster_command
      when: install_calico_custom_resource is succeeded

    - name: Save join command to file
      template:
        src: joincluster.j2
        dest: "{{ join_cluster_remote_src }}"
      when: join_cluster_command is succeeded


    - name: Check if Helm is installed
      command: helm version
      register: helm_version
      failed_when: false
      changed_when: false

    - name: Install Helm if not installed
      shell: curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
      when: helm_version.rc != 0

- name: Worker Node Setup
  hosts: worker_nodes
  become: yes
  gather_facts: yes
  vars:
    join_cluster_remote_src: /tmp/joincluster
  tasks:

    - name: Check if worker node is already part of the cluster
      shell: "kubectl get nodes | grep $(hostname)"
      register: worker_already_joined
      failed_when: false
      changed_when: false

    - name: Debug message if node is already joined
      debug:
        msg: "Node {{ inventory_hostname }} is already part of the cluster."
      when: worker_already_joined.rc == 0

    - name: Copy the join command to server location
      copy:
        src: joincluster
        dest: "{{ join_cluster_remote_src }}"
        mode: '0777'
      when: worker_already_joined.rc != 0

    - name: Join the node to the cluster
      command: sh {{ join_cluster_remote_src }}
      when: worker_already_joined.rc != 0
      ignore_errors: yes
      register: join_result

    - name: Debug message if join command fails
      debug:
        msg: "Joining node {{ inventory_hostname }} to the cluster failed with error: {{ join_result.stderr }}"
      when: join_result is failed

